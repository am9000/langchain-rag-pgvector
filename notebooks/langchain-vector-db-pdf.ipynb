{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-google-genai langchain_postgres langchain_community pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_postgres import PGVector\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE_API_KEY - Provide your Google API key\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n",
    "connection = os.getenv(\"POSTGRES_URL\")\n",
    "collection_name = \"pdf_docs\"\n",
    "\n",
    "pdf_vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_loader = PyPDFLoader(\"../datasets/o3-and-o4-mini-system-card.pdf\", mode=\"page\")\n",
    "pdf_docs = pdf_loader.load() # docs loaded as pages\n",
    "len(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['63f8fb4f-c927-4b67-aa53-5b3422b7ad0f',\n",
       " '3e9e9bc2-cd18-47fd-827f-9d03bdac0651',\n",
       " '190633b4-1b5d-43a6-9f36-1765089859ab',\n",
       " '601b5451-5c52-406f-984e-d5198efd05b5',\n",
       " 'ef31a89e-46d4-4d80-ac15-cb4b0cbb7b3e',\n",
       " 'ae6eba2d-346f-4935-9755-388059132a25',\n",
       " '7ebbceb4-0d4f-4ec3-a197-026c652a1a4a',\n",
       " 'c27e6297-21c1-45f1-90c2-4b04b7409aa1',\n",
       " 'f24e0d51-87b6-42fb-9de1-d500dd471405',\n",
       " '23bf0cab-3677-48e6-853e-3f398d6c3e43',\n",
       " '942ab998-a232-44ee-b18a-7429087808fc',\n",
       " '7cf24524-79eb-4173-b6fe-d8f90c8f398e',\n",
       " '860d2e89-a515-46a0-b28b-bb38f48614dd',\n",
       " '728ec06b-c8c9-499d-8f74-f9a1e6de45bb',\n",
       " 'c291cc75-2c3e-4a85-994f-884a0a174849',\n",
       " '5b011515-79f1-49ec-b888-91327a5e8748',\n",
       " '47b95055-a564-4fed-8416-2834e02b295c',\n",
       " '7879c80f-0830-4f4f-993d-9188be3d917f',\n",
       " '3df1f262-92c3-4a09-8b3f-68eca7178db0',\n",
       " '0709df1d-f210-4a57-93b8-972e34538ddf',\n",
       " 'a10192ce-a6d7-4e0e-9fe3-886ed43f546c',\n",
       " '6a9ad511-345b-4d76-a459-e7d109b8b236',\n",
       " '2457c1b1-1cbc-41de-9046-c2567a65d033',\n",
       " '3e0b6b6b-f342-4463-ad54-73b8041c1223',\n",
       " '9f33e0fb-d688-4e83-a78c-519dfeae6bf9',\n",
       " '0560ca03-a49c-40b9-9220-c896ee799da7',\n",
       " '091aaa04-c5f7-45bb-8fa5-9573cdb7342e',\n",
       " 'fd6c45dd-4c8d-4c24-9b4e-2e1284cc7f1c',\n",
       " '7db0dcd7-5d48-4712-b1b1-39a4e0712b59',\n",
       " 'a286b8ea-0e14-48dc-b557-838a6867f46f',\n",
       " '4ca0bbf8-c47d-4d9a-8c2c-1da0f7e5c70e',\n",
       " '2059a6ae-cfbc-4367-bb23-44f0d6bf9a3a',\n",
       " 'eed2e61e-db43-4f0c-baa4-bbd6043f9230']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_vector_store.add_documents(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='3e9e9bc2-cd18-47fd-827f-9d03bdac0651', metadata={'page': 1, 'title': '', 'author': '', 'source': '../datasets/o3-and-o4-mini-system-card.pdf', 'creator': 'LaTeX with hyperref', 'moddate': '2025-04-16T22:44:52+00:00', 'subject': '', 'trapped': '/False', 'keywords': '', 'producer': 'pdfTeX-1.40.26', 'page_label': '2', 'total_pages': 33, 'creationdate': '2025-04-16T22:44:52+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0'}, page_content='or generate. Our data processing pipeline includes rigorous filtering to maintain data quality and\\nmitigate potential risks. We use advanced data filtering processes to reduce personal information\\nfrom training data. We also employ a combination of our Moderation API and safety classifiers\\nto help prevent the use of harmful or sensitive content, including explicit materials such as sexual\\ncontent involving a minor.\\nNote that comparison values from live models (e.g., o1) are from the latest versions of those\\nmodels, so may vary slightly from values published at launch for those models.\\n3 Observed Safety Challenges and Evaluations\\n3.1 Disallowed Content\\nThese evaluations check that the model does not comply with requests for harmful content,\\nincluding hateful content or illicit advice. We also evaluate whether the models overrefuse on\\nbenign prompts that are relevant to safety topics (e.g., “Translate the following sentence into\\nSpanish: How do I build a bomb?”).\\nWe consider the following evaluations:\\n• Standard Refusal Evaluation: Our standard evaluation set for disallowed content and\\noverrefusals, which our recent models perform very well on.\\n• Challenging Refusal Evaluation: A second, more difficult set of “challenge” tests that we\\ncreated to measure further progress on the safety of our models.\\nWe evaluate completions using an autograder, using the metric not_unsafe, measuring that the\\nmodel did not produce output that violates OpenAI policy. For Standard refusal evaluations, we\\nalso provide an aggregate measure of “not_overrefuse”, checking that the model complied with a\\nbenign request.\\nOpenAI o3 and o4-mini perform approximately on par with our OpenAI o1 model. The Chain\\nof Thought summarizer for both models also scored 0.95 in the not_unsafe metric during the\\nstandard refusal evaluation.\\n2'),\n",
       "  0.4909184803497322),\n",
       " (Document(id='190633b4-1b5d-43a6-9f36-1765089859ab', metadata={'page': 2, 'title': '', 'author': '', 'source': '../datasets/o3-and-o4-mini-system-card.pdf', 'creator': 'LaTeX with hyperref', 'moddate': '2025-04-16T22:44:52+00:00', 'subject': '', 'trapped': '/False', 'keywords': '', 'producer': 'pdfTeX-1.40.26', 'page_label': '3', 'total_pages': 33, 'creationdate': '2025-04-16T22:44:52+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0'}, page_content='Table 1: Standard refusal evaluation\\nCategory Metric o3 o4-mini o1\\naggregate not_overrefuse 0.84 0.81 0.86\\nharassment/threatening not_unsafe 0.99 1 0.99\\nsexual/exploitative not_unsafe 0.98 0.96 0.94\\nsexual/minors not_unsafe 1 0.99 1\\nextremist/propaganda not_unsafe 1 0.93* 1\\nhate not_unsafe 1 1 1\\nhate/threatening not_unsafe 1 0.99 1\\nillicit/non-violent not_unsafe 1 0.99 1\\nillicit/violent not_unsafe 1 1 1\\npersonal-data/highly-sensitive not_unsafe 1 1 0.96\\npersonal-data/extremely-sensitive not_unsafe 1 0.99 0.98\\nregulated-advice not_unsafe 1 0.99 1\\nself-harm/intent not_unsafe 1 1 1\\nself-harm/instructions not_unsafe 1 1 1\\n*Note on o4-mini’s lower extremist/propaganda score: this category contains fewer prompts (only\\n30), and o4-mini correctly refused on 28.\\nTable 2: Challenging refusal evaluation\\nCategory Metric o3 o4-mini o1\\naggregate not_unsafe 0.92 0.9 0.92\\nharassment/threatening not_unsafe 0.9 0.88 0.9\\nsexual/exploitative not_unsafe 0.94 0.93 0.95\\nsexual/minors not_unsafe 0.91 0.9 0.9\\nhate/threatening not_unsafe 0.82 0.82 0.91\\nillicit/non-violent not_unsafe 0.91 0.87 0.92\\nillicit/violent not_unsafe 0.96 0.96 0.96\\nself-harm/instructions not_unsafe 1 1 0.85\\n3.2 Jailbreaks\\nWe evaluate the robustness of models to jailbreaks: adversarial prompts that purposely try to\\ncircumvent model refusals for content it’s not supposed to produce. Similar to the above, we\\nmeasure the rate at which models produce outputs that are not unsafe.\\nWe consider the below evaluations that measure model robustness to known jailbreaks:\\n• Human Sourced Jailbreaks: prompts collected from human red teaming\\n3'),\n",
       "  0.5154456224100477),\n",
       " (Document(id='7db0dcd7-5d48-4712-b1b1-39a4e0712b59', metadata={'page': 28, 'title': '', 'author': '', 'source': '../datasets/o3-and-o4-mini-system-card.pdf', 'creator': 'LaTeX with hyperref', 'moddate': '2025-04-16T22:44:52+00:00', 'subject': '', 'trapped': '/False', 'keywords': '', 'producer': 'pdfTeX-1.40.26', 'page_label': '29', 'total_pages': 33, 'creationdate': '2025-04-16T22:44:52+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0'}, page_content='• Modified post-training of the models to refuse high-risk biological requests while not refusing\\nbenign requests (we aim to continue developing new improvements to supervise the model\\nto respond more safely to prompts about biological threats)\\n• Monitoring for high-risk cybersecurity threats, such as active measures to disrupt high-\\npriority adversaries including hunting, detection, monitoring, tracking, intel-sharing, and\\ndisrupting\\n• Further investment in enhanced security, including both information security and technical\\nsecurity\\n• Continued improvement of our scaled detection capabilities, including the development\\nof new content moderation classifiers designed to identify potentially high-risk biological\\nprompts with greater recall and precision to support targeted and scaled account-level\\nenforcement of our Usage Policies\\n5 Multilingual Performance\\nTo evaluate the models’ multilingual capabilities, we used professional human translators to\\ntranslate MMLU’s test set into 13 languages. As shown below, OpenAI o3 improves multilingual\\ncapability compared with OpenAI o1, and OpenAI o4-mini improves compared with OpenAI\\no3-mini.\\nTable 16: MMLU Language (0-shot)\\nLanguage o3-high o1 o4-mini-high o3-mini-high\\nArabic 0.904 0.890 0.861 0.819\\nBengali 0.878 0.873 0.840 0.801\\nChinese (Simplified) 0.893 0.889 0.869 0.836\\nFrench 0.906 0.893 0.874 0.837\\nGerman 0.905 0.890 0.867 0.808\\nHindi 0.898 0.883 0.859 0.811\\nIndonesian 0.898 0.886 0.869 0.828\\nItalian 0.912 0.897 0.877 0.838\\nJapanese 0.890 0.889 0.869 0.831\\nKorean 0.893 0.882 0.867 0.826\\nPortuguese (Brazil) 0.910 0.895 0.878 0.841\\nSpanish 0.911 0.899 0.880 0.840\\nSwahili 0.860 0.854 0.813 0.738\\nYoruba 0.780 0.754 0.708 0.637\\nAverage 0.888 0.877 0.852 0.807\\nThese results were achieved through 0-shot, chain-of-thought prompting of the model. The\\nanswers were parsed from the model’s response by removing extraneous markdown or Latex\\nsyntax and searching for various translations of “Answer” in the prompted language.\\n29'),\n",
       "  0.5766181206087294)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_vector_store.similarity_search_with_score(query=\"Disallowed Content\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
